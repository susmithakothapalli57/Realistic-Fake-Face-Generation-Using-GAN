# Generating Fake Faces with DCGAN

# CelebFaces Attributes (CelebA) Dataset
https://www.kaggle.com/jessicali9530/celeba-dataset

CelebFaces Attributes Dataset (CelebA) is a large-scale face attributes dataset with more than 200K celebrity images
import numpy as np
import cv2
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import os

from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img
from tensorflow.keras.preprocessing.image import img_to_array, array_to_img 
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, SeparableConv2D, MaxPooling2D, Lambda
from tensorflow.keras.layers import Flatten, Dense, Dropout, BatchNormalization
from tensorflow.keras.layers import Conv2DTranspose, Conv2D, add, concatenate
from tensorflow.keras.layers import LeakyReLU, Activation, Reshape
from tensorflow.keras.utils import plot_model
from tensorflow.keras.optimizers import Adam 
from tensorflow.keras.callbacks import ModelCheckpoint,ReduceLROnPlateau
attributes = pd.read_csv('/kaggle/input/celeb-images/list_attr_celeba.csv')
bboxes = pd.read_csv('/kaggle/input/celeb-images/list_bbox_celeba.csv')
partition = pd.read_csv('/kaggle/input/celeb-images/list_eval_partition.csv')
landmarks = pd.read_csv('/kaggle/input/celeb-images/list_landmarks_align_celeba.csv')
base_directory = '/kaggle/input/celeb-images/img_align_celeba/img_align_celeba'
#base_directory = 'D:\GAN\GAN_Facedataset'
import glob
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
%matplotlib inline

images = []
for img_path in glob.glob('/kaggle/input/celeb-images\\img_align_celeba\\img_align_celeba/*.jpg'):
    images.append(mpimg.imread(img_path))
images = images[:20]
plt.figure(figsize=(20,10))
columns = 5
for i, image in enumerate(images):
    plt.subplot(len(images) / columns + 1, columns, i + 1)
    plt.axis('off')
    #fig.tight_layout() 
    plt.imshow(image)
# Reading list_landmarks_align_celeba.csv
landmarks_df = pd.read_csv('/kaggle/input/celeb-images/list_landmarks_align_celeba.csv')
landmarks_df.head()
# Plotting Landmarks
paths_to_images = '/kaggle/input/celeb-images/img_align_celeba/img_align_celeba/000008.jpg'


#current_landmarks = landmarks.query('image_id == "{}"'.format(paths_to_images.split('\\')[-1]))
#print("Current landmark ; ",current_landmarks)


eye_x, eye_y, eye_w, eye_h = np.array(landmarks.iloc[:, 1:5])[0]
nose_x,	nose_y,	leftmouth_x, leftmouth_y, rightmouth_x, rightmouth_y = np.array(landmarks.iloc[:, 5:])[0]

left_eye = (eye_x, eye_y)
right_eye = (eye_w, eye_h)
nose = (nose_x + 10,nose_y)
left_mounth = (leftmouth_x, leftmouth_y)
right_mounth = (rightmouth_x, rightmouth_y)

example_image = cv2.imread(paths_to_images)
original_image = example_image.copy()


example_image = cv2.cvtColor(example_image, cv2.COLOR_BGR2RGB)

example_image = cv2.line(example_image, left_eye, right_eye, (0, 255, 255),1)
example_image = cv2.line(example_image, left_eye, nose, (0, 255, 255), 1)
example_image = cv2.line(example_image, right_eye, nose, (0, 255, 255), 1)
example_image = cv2.line(example_image, nose, left_mounth,(0, 255, 255), 1)
example_image = cv2.line(example_image, nose, right_mounth, (0, 255, 255), 1)

plt.figure(figsize = (10, 20))
plt.subplot(1,2,1)
plt.axis('off')
plt.title('original image')
plt.imshow(original_image)
plt.subplot(1,2,2)
plt.axis('off')
plt.title('Image with landmarks')
plt.imshow(example_image)


# Reading Bounding Box coordinates list_bbox_celeba.csv  
bboxes_df = pd.read_csv('/kaggle/input/celeb-images/list_bbox_celeba.csv')
bboxes_df.head()
# Plotting Bounding Box Cordinates
current_bbox = bboxes.query('image_id == "{}"'.format(paths_to_images.split('/')[-1]))
print(current_bbox)
x, y, w, h = np.array(current_bbox.iloc[:, 1:])[0]

example_image = cv2.rectangle(example_image, (x - w, y ), (w , h ), (0, 255, 255), 1)

plt.figure(figsize = (10, 20))
plt.subplot(1,2,1)
plt.axis('off')
plt.title('original image')
plt.imshow(original_image)
plt.subplot(1,2,2)
plt.axis('off')
plt.title('Image with bbox and landmarks')
plt.imshow(example_image)

# Reading list_eval_partition.csv

partition_df = pd.read_csv('/kaggle/input/celeb-images/list_eval_partition.csv')
partition_df.head()
# Types of Partitions
partition_df['partition'].value_counts()
# Have 3 partitions  (partition is just recomended parameter of dataset distribution)
train_images = partition.query('partition == 0')
valid_images = partition.query('partition == 1')
test_images = partition.query('partition == 2')


# Reading list_attr_celeba.csv
attributes_df = pd.read_csv('/kaggle/input/celeb-images/list_attr_celeba.csv')
attributes_df.head()
# Create the discriminator
It maps a 64x64 image to a binary classification score.

After receiving all the images, fake and real, the Discriminator returns probabilities, a number in the range of 0 and 1, 1 representing a prediction of authenticity and 0 representing fake


The research shows that image generation is possible with relatively low input quality (64x64 pixels) 

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
import matplotlib.pyplot as plt
import os

discriminator = keras.Sequential(
    [
        keras.Input(shape=(128, 128, 3)),
        layers.Conv2D(64, kernel_size=4, strides=2, padding="same"),
        layers.LeakyReLU(alpha=0.2),
        layers.Conv2D(128, kernel_size=4, strides=2, padding="same"),
        layers.LeakyReLU(alpha=0.2),
        layers.Conv2D(128, kernel_size=4, strides=2, padding="same"),
        layers.LeakyReLU(alpha=0.2),
        layers.Conv2D(256, kernel_size=4, strides=2, padding="same"),
        layers.LeakyReLU(alpha=0.2),
        layers.Flatten(),
        layers.Dropout(0.2),
        layers.Dense(1, activation="sigmoid"),
    ],
    name="discriminator",
)
discriminator.summary()

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

latent_dim = 100  # Latent space dimension

generator = keras.Sequential(
    [
        keras.Input(shape=(latent_dim,)),  # Input latent vector
        layers.Dense(8 * 8 * 256),  # Dense layer to match 8x8x256
        layers.Reshape((8, 8, 256)),  # Reshape to 8x8x256
        layers.Conv2DTranspose(256, kernel_size=4, strides=2, padding="same"),  # 8x8 -> 16x16
        layers.LeakyReLU(alpha=0.2),
        layers.Conv2DTranspose(128, kernel_size=4, strides=2, padding="same"),  # 16x16 -> 32x32
        layers.LeakyReLU(alpha=0.2),
        layers.Conv2DTranspose(64, kernel_size=4, strides=2, padding="same"),  # 32x32 -> 64x64
        layers.LeakyReLU(alpha=0.2),
        layers.Conv2DTranspose(32, kernel_size=4, strides=2, padding="same"),  # 64x64 -> 128x128
        layers.LeakyReLU(alpha=0.2),
        layers.Conv2D(3, kernel_size=5, padding="same", activation="sigmoid"),  # Final RGB output
    ],
    name="generator",
)
generator.summary()

dataset = keras.preprocessing.image_dataset_from_directory(
    "/kaggle/input/celeb-images/img_align_celeba/img_align_celeba", label_mode=None, image_size=(128, 128), batch_size=32
)
dataset = dataset.map(lambda x: x / 255.0)

# Override train_step
class GAN(keras.Model):
    def __init__(self, discriminator, generator, latent_dim):
        super(GAN, self).__init__()
        self.discriminator = discriminator
        self.generator = generator
        self.latent_dim = latent_dim

    def compile(self, d_optimizer, g_optimizer, loss_fn):
        super(GAN, self).compile()
        self.d_optimizer = d_optimizer
        self.g_optimizer = g_optimizer
        self.loss_fn = loss_fn
        self.d_loss_metric = keras.metrics.Mean(name="d_loss")
        self.g_loss_metric = keras.metrics.Mean(name="g_loss")

    @property
    def metrics(self):
        return [self.d_loss_metric, self.g_loss_metric]

    def train_step(self, real_images):
        # Sample random points in the latent space
        batch_size = tf.shape(real_images)[0]
        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))

        # Decode them to fake images
        generated_images = self.generator(random_latent_vectors)

        # Combine them with real images
        combined_images = tf.concat([generated_images, real_images], axis=0)

        # Assemble labels discriminating real from fake images
        labels = tf.concat(
            [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0
        )
        # Add random noise to the labels - important trick!
        labels += 0.05 * tf.random.uniform(tf.shape(labels))

        # Train the discriminator
        with tf.GradientTape() as tape:
            predictions = self.discriminator(combined_images)
            d_loss = self.loss_fn(labels, predictions)
        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)
        self.d_optimizer.apply_gradients(
            zip(grads, self.discriminator.trainable_weights)
        )

        # Sample random points in the latent space
        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))

        # Assemble labels that say "all real images"
        misleading_labels = tf.zeros((batch_size, 1))

        # Train the generator (note that we should *not* update the weights
        # of the discriminator)!
        with tf.GradientTape() as tape:
            predictions = self.discriminator(self.generator(random_latent_vectors))
            g_loss = self.loss_fn(misleading_labels, predictions)
        grads = tape.gradient(g_loss, self.generator.trainable_weights)
        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))

        # Update metrics
        self.d_loss_metric.update_state(d_loss)
        self.g_loss_metric.update_state(g_loss)
        return {
            "d_loss": self.d_loss_metric.result(),
            "g_loss": self.g_loss_metric.result(),
        }
# Create a callback that periodically saves generated images

import tensorflow as tf
from tensorflow import keras
import matplotlib.pyplot as plt

class GANMonitor(keras.callbacks.Callback):
    def __init__(self, num_img=3, latent_dim=100):  # Update latent_dim to 100
        self.num_img = num_img
        self.latent_dim = latent_dim

    def on_epoch_end(self, epoch, logs=None):
        # Generate random latent vectors (input to the generator)
        random_latent_vectors = tf.random.normal(shape=(self.num_img, self.latent_dim))
        
        # Generate images from the random latent vectors
        generated_images = self.model.generator(random_latent_vectors)
        
        # Scale images from [0, 1] to [0, 255]
        generated_images = (generated_images * 255).numpy().astype("uint8")
        
        # Save the generated images
        for i in range(self.num_img):
            img = keras.preprocessing.image.array_to_img(generated_images[i])
            img.save(f"generated_img_{epoch:03d}_{i}.png")
        
        # Plot the generated images
        plt.figure(figsize=(10, 10))
        for i in range(self.num_img):
            plt.subplot(1, self.num_img, i + 1)
            plt.imshow(generated_images[i])
            plt.axis('off')
        plt.savefig(f"image_at_epoch_{epoch:04d}.png")
        plt.show()

# Train the end-to-end model

 Adam optimizer with a learning rate of 0.002. This is as per the original research paper on DCGANs. 
 Link: https://arxiv.org/abs/1511.06434
 epochs = 50  # In practice, use ~100 epochs

gan = GAN(discriminator=discriminator, generator=generator, latent_dim=latent_dim)
gan.compile(
    d_optimizer=keras.optimizers.Adam(learning_rate=0.0001),
    g_optimizer=keras.optimizers.Adam(learning_rate=0.0001),
    loss_fn=keras.losses.BinaryCrossentropy(),
)

gan.fit(
    dataset, epochs=epochs, callbacks=[GANMonitor(num_img=10, latent_dim=latent_dim)]
)
# Display a single image using the epoch number
def display_image(epoch_no):
  return PIL.Image.open('image_at_epoch_{:04d}.png'.format(epoch_no))
import glob
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
%matplotlib inline

images = []
for img_path in glob.glob('/kaggle/working/*.png'):
    images.append(mpimg.imread(img_path))

plt.figure(figsize=(20,10))
columns = 20
for i, image in enumerate(images):
    plt.subplot(int(len(images) / columns) + 1, columns, i + 1)
    plt.axis('off')
    #fig.tight_layout() 
    plt.imshow(image)
import matplotlib.pyplot as plt
import os
from PIL import Image

# Specify the path to your working directory
working_dir = "/kaggle/working"

# List all files in the working directory
files = os.listdir(working_dir)

# Filter image files (e.g., .jpg, .png)
image_files = [file for file in files if file.endswith(('.png', '.jpg', '.jpeg'))]

# Number of images
num_images = len(image_files)

# Parameters for pagination
images_per_page = 20  # Number of images per figure
images_per_row = 5    # Number of images per row
num_rows = (images_per_page + images_per_row - 1) // images_per_row  # Rows per page
num_pages = (num_images + images_per_page - 1) // images_per_page   # Total pages

# Display images page by page
for page in range(num_pages):
    start_idx = page * images_per_page
    end_idx = min(start_idx + images_per_page, num_images)
    images_to_display = image_files[start_idx:end_idx]
    
    # Create a figure for the current page
    fig, axes = plt.subplots(num_rows, images_per_row, figsize=(15, 3 * num_rows))
    axes = axes.ravel()  # Flatten axes for easy iteration

    # Display images on the current page
    for i, img_file in enumerate(images_to_display):
        img_path = os.path.join(working_dir, img_file)
        img = Image.open(img_path)
        axes[i].imshow(img)
        axes[i].set_title(img_file, fontsize=8)
        axes[i].axis('off')

    # Turn off unused axes
    for i in range(len(images_to_display), len(axes)):
        axes[i].axis('off')

    # Adjust layout and display the page
    plt.tight_layout()
    plt.suptitle(f"Page {page + 1} / {num_pages}", fontsize=16, y=1.02)
    plt.show()

import os
import shutil

# Specify the working directory and output path
working_dir = "/kaggle/working"
output_dir = "/kaggle/working/images_to_download"

# Create a folder for images to download
os.makedirs(output_dir, exist_ok=True)

# Move image files to the output directory
for file in os.listdir(working_dir):
    if file.endswith(('.png', '.jpg', '.jpeg')):
        shutil.copy(os.path.join(working_dir, file), os.path.join(output_dir, file))

# Compress the images folder into a zip file
shutil.make_archive('images_to_download', 'zip', output_dir)

from IPython.display import FileLink, display
import os
import shutil
display(FileLink('images_to_download.zip'))
discriminator.save('/kaggle/working/discriminator_model.h5')
generator.save('/kaggle/working/generator_model.h5')
gan.save('/kaggle/working/gan_model.h5')
import os
import zipfile

# Specify the path to your working directory
working_dir = "/kaggle/working"

# List all files in the working directory
files = os.listdir(working_dir)

# Filter model files (e.g., .h5, .pth, .joblib, etc.)
model_files = [file for file in files if file.endswith(('.h5', '.pth', '.joblib', '.sav', '.model'))]

# Specify the name of the zip file
zip_filename = "models.zip"

# Create a zip file containing all model files
with zipfile.ZipFile(zip_filename, 'w') as zipf:
    for model_file in model_files:
        zipf.write(os.path.join(working_dir, model_file), model_file)

print(f"Created zip file: {zip_filename}")

# Display a download link for the zip file
from IPython.display import FileLink
FileLink(zip_filename)

import os

# Specify the path to the working directory
working_dir = "/kaggle/working"  # Change this path if needed

# List all files in the working directory
files = os.listdir(working_dir)

# Print the list of files
for file in files:
    print(file)

import numpy as np
import cv2
from skimage.metrics import structural_similarity as ssim
from math import log10, sqrt

# Function to calculate PSNR
def calculate_psnr(img1, img2):
    mse = np.mean((img1 - img2) ** 2)
    if mse == 0:
        return float('inf')
    max_pixel = 255.0
    psnr = 20 * log10(max_pixel / sqrt(mse))
    return psnr

# Function to calculate SSIM
def calculate_ssim(img1, img2):
    img1_gray = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)
    img2_gray = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)
    return ssim(img1_gray, img2_gray)

# Load generated and real images
img_generated = cv2.imread('/kaggle/working/generated_img_049_9.png')  # Replace with the actual path
img_real = cv2.imread('/kaggle/input/celeb-images/img_align_celeba/img_align_celeba/000009.jpg')  # Replace with the actual path

# Check if images are loaded correctly
if img_generated is None or img_real is None:
    print("Error loading images. Check the file paths.")
else:
    # Resize real image to match the generated image size (128x128)
    img_real_resized = cv2.resize(img_real, (128, 128))

    # Calculate PSNR and SSIM
    psnr_value = calculate_psnr(img_real_resized, img_generated)
    ssim_value = calculate_ssim(img_real_resized, img_generated)

    print(f"PSNR: {psnr_value:.2f} dB")
    print(f"SSIM: {ssim_value:.4f}")
    





